Introduction- Patrick (3 mins)
Hello & welcome. My name is Patrick Dobry and I represent Group 6. Our team members are Kylie Hicks, Kaiya Hull & David Hyde. We chose movies as our subject of exploration for the machine learning project & final. Imagine yourself as a production office executive and needing information on new releases to determine the gross amount of revenue your company would make for a particular movie. This is the crystal ball that we created with our project. It is also fun to explore new releases as we head into the summer blockbuster season. The type of regression models we considered using included Linear, Lasso, and Ridge Regression. We will also have a dashboard with a user interface that allows users to enter details regarding a pending release and the machine learning model will predict the movie's gross revenue. At the end of our presentation, we will demonstrate a real live movie, Flowers of the Killer Moon, by Martin Scorsese & Leonardo DiCaprio to predict the revenue. Now to talk more about our data exploration phase, here is Kylie Hicks. 

Data Exploration, Database, & Cleaning- Kylie (3 mins)
The main movie dataset was found on Kaggle. The dataset was originally scraped from the IMDB website. IMBD is an online database that contains information related to movies, TV series, video games, as well as streaming content. This particular dataset caught our eyes because it is robust and we could seemingly draw direct conclusions from linear regression models.
Additional datasets containing the birthdates, number of nominations, and number of awards won by the lead actor/actress listed for each movie in the movie dataset were obtained by webscraping Wikipedia pages. Which is an online encyclopedia allowing free public access. Information is provided by volunteers and contributors through open collaboration. The dataset containing the birthdates was obtained by a script that visited each actors' individual Wikipedia page. The second dataset, containing the Academy Award nominations and awards won for leading and supporting roles since 1927, was obtained by scraping Academy Award Nominations.
Initial cleaning of the movie dataset from Kaggle included removing null values. The released column contained both the date of the movie's release and the country of release. To obtain the release date only, we used the str.replace method and RegEx, then converted the date to the month only using pandas dt.month. Since the dataset contains monetary information in the budget and gross revenue columns spanning movies released from 1980 to 2020, we wanted to account for inflation. To do this, we used the cpi.inflate from a python library that adjusts U.S. dollars for inflation using the Consumer Price Index.
When pulling data tables from our database, we merged the movies table with the released_dayofweek to obtain the day of week each movie was released. Additionally, we merged the actors_bday with the actor_awards table to essentially create a profile for each movie's starring actor. Since the information scraped from Wikipedia's Academy Awards included all actors who received a nomination or award since 1921, any actor who did not have a value in the actor_awards table is reasoned to have neither been nominated nor awarded and their values were filled with 0's accordingly. These two dataframes were then merged to create the final dataset including the cleaned information for movies and actors. Upon investigation, we removed movies with the following ratings: NC-17, Not Rated, TV-MA, Unrated, and X. These movies made up a small portion of the sample and were likely to skew our results since we were focusing on theater releases. Since some columns had numerous unique values, to prepare for the machine learning, we binned the following data: genre, director, writer, star, and company.

Machine Learning Model- David (4 mins)

We chose to use a Linear Regression model for our analysis because the gross income variable we were targeting is a continuous variable, meaning it cannot be sorted into categories. We trained and tested our data on three different linear regression models, and the model that performed the best was the Ridge Regression model. Ridge regression is a linear regression model that better estimates variable coefficients when multiple variables are highly correlated, but still independent of each other. 

There are limits to a linear regression model. First, these models are heavily influenced by the presence of outliers in a dataset, and this can impact the fit of the regression line as well as the final accuracy score. Also, linear regression assumes that there is a linear relationship between the target variable and each independent feature variable, and if that is not the case, it can lower the accuracy of the model.

When analyzing our dataset, we noticed that our target variable, gross income, had a strong positive skew, meaning most of the data concentrated around a smaller value while the higher values trail off in a “tail” towards the positive axis. In order for our Ridge Regression model to be accurate, we had to transform our target variable to give it a more “normal” distribution. We did this by using the square root of the gross income while training and testing our linear regression model.

Our model produced an r2 score of 0.58 and a mean squared error of approximately 22 million. The r2 score is commonly used to describe the accuracy of a linear regression model, and it shows how well a linear model fits a set of data. In this case, our model shows 58% of the total variance in the dependent variable was predictable from the independent variables. The mean squared error describes how close, on average, our regression line is to the original target variables. While an error of 22 million may seem alarming, the gross income variable that is being measured is commonly in the hundred-million range.



Conclusion & Demo- Kaiya (5 mins)
A.	Describe Dash Plotly
B.	Model demo:
 .	Avatar 2
a.	Top Gun
