# Group Project May 2022 Group #6
**Machine Learning Model:**

The features for the machine learning model were spread across four tables in the database, so SQLAlchemy was used to call and filter the tables so they could be merged into one dataframe for cleaning and preprocessing. For the data preprocessing we did the following:
  - The rows with missing values were removed using the .dropna() method, reducing the number of rows to 5,421
  - We isolated the month of the movie’s release using the .str.split() method to split the data in the column at the “(“ to create a new column with only the date. Then using Pandas .to_datetime() and the dt.month methods, we isolated only the month of the movie’s release.
  - To account for inflation, we used a lambda function to apply the Consumer Price Index (cpi) library to adjust the budget and gross revenue dollar values.
  - Columns with many unique categorical values such as writer, director, star, and company had the majority of less frequent values binned into an “Other” category to reduce the number of columns in the dataframe once encoded
  - Actor age and movie release date were used to generate a new “star_age” column with the age of the actor at the time of movie release
  - Nomination and Award columns had null values replaced with 0 to indicate the lack of actor nominations/awards
  -	Non-feature columns were dropped and columns with categorical data were encoded with OneHotEncoder so they could be input into a linear regression model
  -	Data was split into training and testing data, and feature values were scaled using a RobustScaler

After analyzing our data, we determined that the best features to include in our model would be the columns with continuous values, such as the runtime and budget (adjusted for inflation) because continuous values are more easily processed by linear regression. We also wanted continuous values that could represent the actor variable, so we generated an age feature for the actors, as well as nominations for Oscars and awards won. Finally, we chose categorical features such as rating, actor, company, and month of release because they seemed relevant, and through testing on the Linear Regression model, seemed to improve the model’s accuracy.

Data was split into training and testing data using SciKit Learn’s train_test_split() function, where the features of the model were input as the X value and the square root of the target value (adjusted gross revenue) was input as the y value. We used the square root of target value to account for the data’s strong positive skew. After the data was split, both the training and testing feature values were scaled using SciKit Learn’s RobustScaler() to account for outliers noticed during data exploration.
We chose to use a linear regression model because the target value we are trying to predict is a continuous value. The limitations of the linear regression are that it is limited to linear relationships, only looks at the mean of the dependent variable, is sensitive to outliers, and data must be independent. This mean heavy way of looking at things can easily be skewed. (Source #2)

SciKitLearn  will be used using a multi-linear regression model to train and test the data. We will also use a Lasso & Ridge regression model. Our output labels will be predicted gross revenue. We will also be using a fourth Linear Regression Model that's run through statsmodels instead of SciKitLearn. It reproduces the first Linear Regression model, but also provides a summary statistics table. Training occurred by fitting the Linear Regression models to the scaled training data to predict the training target values. Once the models were trained, they were used to predict the target values of the scaled testing features, and these predictions were compared to the testing target values to generate an r2 score for accuracy. **After testing all models on the final data, it was determined that the Ridge Linear Regression model is the most accurate, so it will be used in the dashboard.** Our model generates an accuracy score of 58%. While we did not achieve our target accuracy score of 70%, we believe that ultimately, the success of a movie is heavily influenced by human behavior, which is difficult to predict with such a simple machine learning model.
